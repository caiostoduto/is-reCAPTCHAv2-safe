{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c22e0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96af23a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = Path(\"../datasets\")\n",
    "shared_images_dir = Path(\"../dataset_shared/images\")\n",
    "\n",
    "max_images = 3000\n",
    "N_FOLDS = 5\n",
    "\n",
    "classification_models8 = [\"yolov8n-cls.pt\", \"yolov8s-cls.pt\", \"yolov8m-cls.pt\", \"yolov8l-cls.pt\", \"yolov8x-cls.pt\"]\n",
    "classification_models11 = [\"yolo11n-cls.pt\", \"yolo11s-cls.pt\", \"yolo11m-cls.pt\", \"yolo11l-cls.pt\", \"yolo11x-cls.pt\"]\n",
    "model_name = classification_models11[0]\n",
    "\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "params = {\n",
    "    \"epochs\": 1,\n",
    "    \"imgsz\": 224,\n",
    "    \"batch\": 10,\n",
    "    \"patience\": 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acd5207",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.dataset_download import DatasetDownloader\n",
    "from utils.load_datasets import load_datasets\n",
    "\n",
    "dataset_downloader = DatasetDownloader(dataset_path)\n",
    "dataset_downloader.download_all()\n",
    "\n",
    "df = load_datasets(dataset_path)\n",
    "display(df.head())\n",
    "display(df['From'].value_counts())\n",
    "display(f\"Total images loaded: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9101d21c",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df['Label'].unique()\n",
    "\n",
    "label_count = {label: 0 for label in labels}\n",
    "\n",
    "updt_df_dict = {\n",
    "    \"Image\": [],\n",
    "    \"Filename\": [],\n",
    "    \"Label\": [],\n",
    "    \"From\": []\n",
    "}\n",
    "\n",
    "# Create shared images directory once (outside the loop)\n",
    "shared_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create symlinks to all images once\n",
    "print(\"Creating shared images directory...\")\n",
    "for idx, row in df.iterrows():\n",
    "    if label_count[row['Label']] < max_images:\n",
    "        src = Path(row['Image']).absolute()\n",
    "        unique_filename = f\"{row['From']}_{row['Filename']}\"\n",
    "        dst = shared_images_dir / unique_filename\n",
    "        \n",
    "        if not dst.exists():\n",
    "            os.symlink(src, dst)\n",
    "        label_count[row['Label']] += 1\n",
    "\n",
    "        updt_df_dict[\"Image\"].append(row[\"Image\"])\n",
    "        updt_df_dict[\"Filename\"].append(row[\"Filename\"])\n",
    "        updt_df_dict[\"Label\"].append(row[\"Label\"])\n",
    "        updt_df_dict[\"From\"].append(row[\"From\"])\n",
    "\n",
    "print(f\"Shared images directory created with {len(list(shared_images_dir.iterdir()))} images\")\n",
    "\n",
    "df = pd.DataFrame(updt_df_dict)\n",
    "df.to_parquet(dataset_path / \"datasets_reduced.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d5e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    display(df['Label'].value_counts())\n",
    "except NameError:\n",
    "    df = pd.read_parquet(os.path.join(dataset_path, 'datasets_reduced.parquet'), engine='pyarrow')\n",
    "    display(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd7ccde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Setup k-fold\n",
    "labels = df['Label'].unique()\n",
    "\n",
    "# Store results from all folds\n",
    "all_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['Label'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Split data for this fold\n",
    "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Train: {len(train_df)}, Val: {len(val_df)}\")\n",
    "    print(f\"Train label distribution:\\n{train_df['Label'].value_counts()}\")\n",
    "    print(f\"Val label distribution:/n{val_df['Label'].value_counts()}\")\n",
    "    \n",
    "    # Create fold-specific dataset structure\n",
    "    dataset_root = Path(f\"../dataset_fold{fold}\")\n",
    "    labels_file = dataset_root / \"labels.txt\"\n",
    "    \n",
    "    dataset_root.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Build list of images with their splits for this fold\n",
    "    all_images = []\n",
    "    \n",
    "    # Add training images\n",
    "    for idx, row in train_df.iterrows():\n",
    "        unique_filename = f\"{row['From']}_{row['Filename']}\"\n",
    "        all_images.append({\n",
    "            'filename': unique_filename,\n",
    "            'label': row['Label'],\n",
    "            'split': 'train'\n",
    "        })\n",
    "    \n",
    "    # Add validation images\n",
    "    for idx, row in val_df.iterrows():\n",
    "        unique_filename = f\"{row['From']}_{row['Filename']}\"\n",
    "        all_images.append({\n",
    "            'filename': unique_filename,\n",
    "            'label': row['Label'],\n",
    "            'split': 'val'\n",
    "        })\n",
    "    \n",
    "    # Create labels file with format: filename label split\n",
    "    with open(labels_file, 'w') as f:\n",
    "        f.write(\"filename/tlabel\\tsplit\\n\")\n",
    "        for img_info in all_images:\n",
    "            f.write(f\"{img_info['filename']}\\t{img_info['label']}\\t{img_info['split']}\\n\")\n",
    "    \n",
    "    # For YOLO classification, create train/val split directories\n",
    "    # with symlinks pointing to the shared images folder\n",
    "    train_dir = dataset_root / \"train\"\n",
    "    val_dir = dataset_root / \"val\"\n",
    "    \n",
    "    # Remove old train/val if they exist\n",
    "    if train_dir.exists():\n",
    "        shutil.rmtree(train_dir)\n",
    "    if val_dir.exists():\n",
    "        shutil.rmtree(val_dir)\n",
    "    \n",
    "    # Create label subdirectories\n",
    "    for label in labels:\n",
    "        (train_dir / label).mkdir(parents=True, exist_ok=True)\n",
    "        (val_dir / label).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create symlinks in train/val pointing to shared images folder\n",
    "    for img_info in all_images:\n",
    "        src = (shared_images_dir / img_info['filename']).absolute()\n",
    "        if img_info['split'] == 'train':\n",
    "            dst = train_dir / img_info['label'] / img_info['filename']\n",
    "        else:\n",
    "            dst = val_dir / img_info['label'] / img_info['filename']\n",
    "        \n",
    "        os.symlink(src, dst)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} dataset created!\")\n",
    "    print(f\"  - Labels file: {labels_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ea212b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Store results from all folds\n",
    "all_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['Label'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Create fold-specific dataset structure\n",
    "    dataset_root = Path(f\"../dataset_fold{fold}\")\n",
    "    labels_file = dataset_root / \"labels.txt\"\n",
    "\n",
    "    project = \"is_recaptchav2_safe/yolo\"\n",
    "    name = f\"{model_name[:-3]}/fold{fold}\"\n",
    "    fold_save_dir = os.path.join(\".\", project, name)\n",
    "\n",
    "    # Initialize fresh model for each fold\n",
    "    model = YOLO(model_name)\n",
    "    model.to('cuda')\n",
    "    \n",
    "    # Train on this fold\n",
    "    results = model.train(\n",
    "        data=str(dataset_root),\n",
    "        epochs=params['epochs'],\n",
    "        imgsz=params['imgsz'],\n",
    "        batch=params['batch'],\n",
    "        patience=params['patience'],\n",
    "        save=True,\n",
    "        project=project,\n",
    "        name=name,\n",
    "        plots=True,\n",
    "        val=True,\n",
    "    )\n",
    "    \n",
    "    # Store results\n",
    "    all_results.append({\n",
    "        'fold': fold + 1,\n",
    "        'results': results,\n",
    "        'final_metrics': results.results_dict if hasattr(results, 'results_dict') else None\n",
    "    })\n",
    "\n",
    "    history = pd.read_csv(os.path.join(fold_save_dir, \"results.csv\"))\n",
    "    # Plot training curves for this fold\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    # Plot loss\n",
    "    axes[0].plot(history['train/loss'], label='Train Loss', marker='o')\n",
    "    axes[0].plot(history['val/loss'], label='Val Loss', marker='s')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title(f'Fold {fold + 1} - Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Plot accuracy\n",
    "    axes[1].plot(history['metrics/accuracy_top1'], label='Top 1 Acc', marker='o')\n",
    "    axes[1].plot(history['metrics/accuracy_top5'], label='Top 5 Acc', marker='s')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title(f'Fold {fold + 1} - Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    # Plot learning rate\n",
    "    axes[2].plot(history['lr/pg0'], label='Learning Rate', marker='o', color='green')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Learning Rate')\n",
    "    axes[2].set_title(f'Fold {fold + 1} - Learning Rate Schedule')\n",
    "    axes[2].set_yscale('log')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(fold_save_dir, 'training_plots.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "    print(f\"Training plots saved to: {os.path.join(fold_save_dir, 'training_plots.png')}\")\n",
    "\n",
    "# Summary of all folds\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(\"K-FOLD CROSS-VALIDATION SUMMARY\")\n",
    "print(f\"{'='*50}\")\n",
    "\n",
    "# Extract and display metrics across folds\n",
    "metrics_df = pd.DataFrame([\n",
    "    {\n",
    "        'Fold': r['fold'],\n",
    "        'Accuracy': r['results'].top1 if hasattr(r['results'], 'top1') else None,\n",
    "        'Top5': r['results'].top5 if hasattr(r['results'], 'top5') else None,\n",
    "        'Fitness': r['results'].fitness if hasattr(r['results'], 'fitness') else None\n",
    "    }\n",
    "    for r in all_results\n",
    "])\n",
    "\n",
    "display(metrics_df)\n",
    "\n",
    "# Calculate average performance\n",
    "print(\"\\nAverage Performance Across Folds:\")\n",
    "for col in metrics_df.columns:\n",
    "    if col != 'Fold' and pd.api.types.is_numeric_dtype(metrics_df[col]):\n",
    "        mean_val = metrics_df[col].mean()\n",
    "        std_val = metrics_df[col].std()\n",
    "        print(f\"{col}: {mean_val:.4f} ± {std_val:.4f}\")\n",
    "\n",
    "for r in all_results:\n",
    "    display(r['results'].save_dir)\n",
    "\n",
    "metrics_df.to_csv(f\"is_recaptchav2_safe_kfold/metrics_{model_name[:-3]}.csv\")\n",
    "\n",
    "with open(f\"is_recaptchav2_safe_kfold/metrics_{model_name[:-3]}.txt\", 'w') as f:\n",
    "    f.write(f\"Folds: {N_FOLDS}\\n\")\n",
    "\n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    for param in params.items():\n",
    "        f.write(f\"{param[0]}: {param[1]}\\n\")\n",
    "    \n",
    "    f.write(\"\\n\")\n",
    "\n",
    "    for col in metrics_df.columns:\n",
    "        if col != 'Fold' and pd.api.types.is_numeric_dtype(metrics_df[col]):\n",
    "            mean_val = metrics_df[col].mean()\n",
    "            std_val = metrics_df[col].std()\n",
    "            f.write(f\"{col}: {mean_val:.4f} ± {std_val:.4f}\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is-recaptchav2-safe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
