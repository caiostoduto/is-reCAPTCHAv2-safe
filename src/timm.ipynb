{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a77518f",
   "metadata": {},
   "source": [
    "# Is reCAPTCHAv2 Safe? - TIMM Implementation\n",
    "\n",
    "**Educational Research Project - UFABC Artificial Intelligence Course**\n",
    "\n",
    "This notebook implements a deep learning classifier using **PyTorch Image Models (timm)** to analyze the viability of reCAPTCHAv2 as a CAPTCHA method.\n",
    "\n",
    "## Model Options\n",
    "You can experiment with different pre-trained models by changing `model_name` in CONFIG:\n",
    "- `efficientnet_b0` - Efficient and fast (default)\n",
    "- `resnet50` - Classic architecture\n",
    "- `vit_small_patch16_224` - Vision Transformer\n",
    "- `convnext_tiny` - Modern ConvNet\n",
    "- `mobilenetv3_large_100` - Lightweight mobile model\n",
    "\n",
    "## Features\n",
    "- Transfer learning with timm pre-trained models\n",
    "- Data augmentation for improved generalization\n",
    "- Early stopping to prevent overfitting\n",
    "- Learning rate scheduling (Cosine Annealing)\n",
    "- MPS/CUDA/CPU support\n",
    "- Training visualization and metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f6ac6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import torch\n",
    "import timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbefd02d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"../datasets\"\n",
    "shared_images_dir = Path(\"../dataset_shared/images\")\n",
    "\n",
    "max_images = 3000\n",
    "N_FOLDS = 5\n",
    "\n",
    "timm_main_models = [\n",
    "    # --- CNNs ---\n",
    "    \"resnet50\",                 # ResNet family\n",
    "    \"resnext50_32x4d\",          # ResNeXt\n",
    "    \"seresnet50\",               # SENet family\n",
    "    \"densenet121\",              # DenseNet\n",
    "    \"efficientnet_b0\",          # EfficientNet\n",
    "    \"mobilenetv3_large_100\",    # MobileNet\n",
    "    \"convnext_base\",            # ConvNeXt\n",
    "    \"regnety_008\",              # RegNet\n",
    "    \"dpn92\",                    # DPN (Dual Path)\n",
    "    \"skresnet50\",               # Selective Kernel conv\n",
    "    \"selecsls60\",               # Selective SLS\n",
    "    \"inception_v3\",             # Inception\n",
    "    \"squeezenet1_1\",            # SqueezeNet\n",
    "\n",
    "    # --- Vision Transformers ---\n",
    "    \"vit_base_patch16_224\",     # ViT\n",
    "    \"deit_base_patch16_224\",    # DeiT\n",
    "    \"swin_base_patch4_window7_224\",  # Swin Transformer\n",
    "    \"beit_base_patch16_224\",    # BEiT\n",
    "    \"beitv2_base_patch16_224\",  # BEiT v2\n",
    "    \"cait_s24_224\",             # CaiT\n",
    "    \"tnt_s_patch16_224\",        # TNT\n",
    "    \"coat_lite_small\",          # CoaT\n",
    "    \"twins_svt_small\",          # Twins-SVT\n",
    "    \"pvt_small\",                # Pyramid Vision Transformer (PVT)\n",
    "    \"crossvit_small_240\",       # CrossViT\n",
    "    \"volo_d1_224\",              # VOLO\n",
    "\n",
    "    # --- Hybrid CNN + Transformer ---\n",
    "    \"coatnet_0\",                # CoAtNet\n",
    "    \"efficientformerv2_s1\",     # EfficientFormerV2\n",
    "    \"nfnet_f0\",                 # NFNet (large CNN hybrid-like)\n",
    "\n",
    "    # --- Lightweight / Mobile ---\n",
    "    \"tinynet_a\",                # TinyNet\n",
    "    \"mnasnet_100\",              # MnasNet\n",
    "    \"hardcorenas_a\",            # HardCoReNAS\n",
    "\n",
    "    # --- Large / High-Performance ---\n",
    "    \"eva_giant_patch14_336\",    # EVA (gigantic ViT model)\n",
    "    \"maxvit_base_tf_224\",       # MaxViT\n",
    "]\n",
    "\n",
    "model_name = 'efficientnet_b0'\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "\n",
    "CONFIG = {\n",
    "    'model_name': model_name,\n",
    "    'img_size': 224,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 2,\n",
    "    'patience': 50,\n",
    "    'lr': 0.001,\n",
    "    'device': 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_workers': 4,\n",
    "    'n_folds': N_FOLDS,  # ADICIONAR\n",
    "    'save_dir': f'is_recaptchav2_safe/timm_experiment/{model_name}'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b37046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T01:23:14.010616Z",
     "start_time": "2025-11-16T01:23:13.093838Z"
    }
   },
   "outputs": [],
   "source": [
    "from utils.dataset_download import DatasetDownloader\n",
    "from utils.load_datasets import load_datasets\n",
    "\n",
    "dataset_downloader = DatasetDownloader(dataset_path)\n",
    "dataset_downloader.download_all()\n",
    "\n",
    "df = load_datasets(dataset_path)\n",
    "display(df.head())\n",
    "display(df['From'].value_counts())\n",
    "display(f\"Total images loaded: {len(df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc9486fe1bfe8cd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T01:23:17.779817Z",
     "start_time": "2025-11-16T01:23:16.410912Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = df['Label'].unique()\n",
    "\n",
    "label_count = {label: 0 for label in labels}\n",
    "\n",
    "updt_df_dict = {\n",
    "    \"Image\": [],\n",
    "    \"Filename\": [],\n",
    "    \"Label\": [],\n",
    "    \"From\": []\n",
    "}\n",
    "\n",
    "# Create shared images directory once (outside the loop)\n",
    "shared_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create symlinks to all images once\n",
    "print(\"Creating shared images directory...\")\n",
    "for idx, row in df.iterrows():\n",
    "    if label_count[row['Label']] < max_images:\n",
    "        src = Path(row['Image']).absolute()\n",
    "        unique_filename = f\"{row['From']}_{row['Filename']}\"\n",
    "        dst = shared_images_dir / unique_filename\n",
    "        \n",
    "        if not dst.exists():\n",
    "            os.symlink(src, dst)\n",
    "        label_count[row['Label']] += 1\n",
    "\n",
    "        updt_df_dict[\"Image\"].append(row[\"Image\"])\n",
    "        updt_df_dict[\"Filename\"].append(row[\"Filename\"])\n",
    "        updt_df_dict[\"Label\"].append(row[\"Label\"])\n",
    "        updt_df_dict[\"From\"].append(row[\"From\"])\n",
    "\n",
    "print(f\"Shared images directory created with {len(list(shared_images_dir.iterdir()))} images\")\n",
    "\n",
    "df = pd.DataFrame(updt_df_dict)\n",
    "df.to_parquet(dataset_path / \"datasets_reduced.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9084d20975c1d594",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T01:23:20.744070Z",
     "start_time": "2025-11-16T01:23:20.737340Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    display(df['Label'].value_counts())\n",
    "except NameError:\n",
    "    df = pd.read_parquet(os.path.join(dataset_path, 'datasets_reduced.parquet'), engine='pyarrow')\n",
    "    display(df['Label'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b06de1170699a6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T01:23:37.417905Z",
     "start_time": "2025-11-16T01:23:23.903545Z"
    }
   },
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Setup k-fold\n",
    "labels = df['Label'].unique()\n",
    "\n",
    "# Store results from all folds\n",
    "all_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['Label'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    # Split data for this fold\n",
    "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Train: {len(train_df)}, Val: {len(val_df)}\")\n",
    "    print(f\"Train label distribution:\\n{train_df['Label'].value_counts()}\")\n",
    "    print(f\"Val label distribution:\\n{val_df['Label'].value_counts()}\")\n",
    "    \n",
    "    # Create fold-specific dataset structure\n",
    "    dataset_root = Path(f\"../dataset_fold{fold}\")\n",
    "    labels_file = dataset_root / \"labels.txt\"\n",
    "    \n",
    "    dataset_root.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Build list of images with their splits for this fold\n",
    "    all_images = []\n",
    "    \n",
    "    # Add training images\n",
    "    for idx, row in train_df.iterrows():\n",
    "        unique_filename = f\"{row['From']}_{row['Filename']}\"\n",
    "        all_images.append({\n",
    "            'filename': unique_filename,\n",
    "            'label': row['Label'],\n",
    "            'split': 'train'\n",
    "        })\n",
    "    \n",
    "    # Add validation images\n",
    "    for idx, row in val_df.iterrows():\n",
    "        unique_filename = f\"{row['From']}_{row['Filename']}\"\n",
    "        all_images.append({\n",
    "            'filename': unique_filename,\n",
    "            'label': row['Label'],\n",
    "            'split': 'val'\n",
    "        })\n",
    "    \n",
    "    # Create labels file with format: filename label split\n",
    "    with open(labels_file, 'w') as f:\n",
    "        f.write(\"filename\\tlabel\\tsplit\\n\")\n",
    "        for img_info in all_images:\n",
    "            f.write(f\"{img_info['filename']}\\t{img_info['label']}\\t{img_info['split']}\\n\")\n",
    "    \n",
    "    # For TIMM classification, create train/val split directories\n",
    "    # with symlinks pointing to the shared images folder\n",
    "    train_dir = dataset_root / \"train\"\n",
    "    val_dir = dataset_root / \"val\"\n",
    "    \n",
    "    # Remove old train/val if they exist\n",
    "    if train_dir.exists():\n",
    "        shutil.rmtree(train_dir)\n",
    "    if val_dir.exists():\n",
    "        shutil.rmtree(val_dir)\n",
    "    \n",
    "    # Create label subdirectories\n",
    "    for label in labels:\n",
    "        (train_dir / label).mkdir(parents=True, exist_ok=True)\n",
    "        (val_dir / label).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Create symlinks in train/val pointing to shared images folder\n",
    "    for img_info in all_images:\n",
    "        src = (shared_images_dir / img_info['filename']).absolute()\n",
    "        if img_info['split'] == 'train':\n",
    "            dst = train_dir / img_info['label'] / img_info['filename']\n",
    "        else:\n",
    "            dst = val_dir / img_info['label'] / img_info['filename']\n",
    "        \n",
    "        os.symlink(src, dst)\n",
    "    \n",
    "    print(f\"Fold {fold + 1} dataset created!\")\n",
    "    print(f\"  - Labels file: {labels_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8392653d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T01:23:44.612747Z",
     "start_time": "2025-11-16T01:23:42.968417Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Configuration\n",
    "\n",
    "print(f\"Using device: {CONFIG['device']}\")\n",
    "print(f\"Model: {CONFIG['model_name']}\")\n",
    "\n",
    "# Create save directory\n",
    "Path(CONFIG['save_dir']).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2253074f",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2025-11-16T01:23:49.336325Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Store results from all folds\n",
    "all_fold_results = []\n",
    "\n",
    "\n",
    "# Training and validation functions (definir FORA do loop)\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    for inputs, labels in pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss / len(pbar):.4f}',\n",
    "            'acc': f'{100. * correct / total:.2f}%'\n",
    "        })\n",
    "\n",
    "    return running_loss / len(train_loader), 100. * correct / total\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc='Validation')\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{running_loss / len(pbar):.4f}',\n",
    "                'acc': f'{100. * correct / total:.2f}%'\n",
    "            })\n",
    "\n",
    "            all_preds.extend(predicted.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    cm = confusion_matrix(all_labels, all_preds)\n",
    "    return running_loss / len(val_loader), 100. * correct / total, cm\n",
    "\n",
    "\n",
    "# INÍCIO DO LOOP DE FOLDS\n",
    "for fold in range(CONFIG['n_folds']):\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"PROCESSING FOLD {fold + 1}/{CONFIG['n_folds']}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # Update data directory for current fold\n",
    "    fold_data_dir = f'../dataset_fold{fold}'\n",
    "    fold_save_dir = os.path.join(CONFIG['save_dir'], f'fold{fold}')\n",
    "    Path(fold_save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Data Transforms\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Load datasets for this fold\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(fold_data_dir, 'train'),\n",
    "        transform=train_transform\n",
    "    )\n",
    "\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(fold_data_dir, 'val'),\n",
    "        transform=val_transform\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    num_classes = len(train_dataset.classes)\n",
    "    class_names = train_dataset.classes\n",
    "\n",
    "    print(f\"\\nDataset Statistics:\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(f\"Classes: {class_names}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "    # Create model using timm (NOVO modelo para cada fold)\n",
    "    model = timm.create_model(\n",
    "        CONFIG['model_name'],\n",
    "        pretrained=True,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    model = model.to(CONFIG['device'])\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=0.01)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=10,\n",
    "        T_mult=2,\n",
    "        eta_min=1e-6\n",
    "    )\n",
    "\n",
    "    print(f\"\\nModel created: {CONFIG['model_name']}\")\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_model_path = os.path.join(fold_save_dir, 'best.pt')\n",
    "    last_model_path = os.path.join(fold_save_dir, 'last.pt')\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"Starting Training - Fold {fold + 1}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{CONFIG['epochs']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, CONFIG['device']\n",
    "        )\n",
    "\n",
    "        # Validate\n",
    "        val_loss, val_acc, cm = validate(\n",
    "            model, val_loader, criterion, CONFIG['device']\n",
    "        )\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['lr'].append(current_lr)\n",
    "\n",
    "        print(f\"\\nEpoch Summary:\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            best_cm = cm\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'fold': fold,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'val_loss': val_loss,\n",
    "                'class_names': class_names\n",
    "            }, best_model_path)\n",
    "            print(f\"✓ New best model saved! Val Acc: {val_acc:.2f}%\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Patience: {patience_counter}/{CONFIG['patience']}\")\n",
    "\n",
    "        # Save last model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'fold': fold,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'class_names': class_names\n",
    "        }, last_model_path)\n",
    "\n",
    "        # Early stopping\n",
    "        if patience_counter >= CONFIG['patience']:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "        \n",
    "    # Save fold results\n",
    "    fold_results = {\n",
    "        'fold': fold + 1,\n",
    "        'best_val_acc': best_val_acc,\n",
    "        'final_val_acc': val_acc,\n",
    "        'final_train_acc': train_acc,\n",
    "        'final_val_loss': val_loss,\n",
    "        'final_train_loss': train_loss,\n",
    "        'epochs_trained': epoch + 1\n",
    "    }\n",
    "    all_fold_results.append(fold_results)\n",
    "\n",
    "    # Save fold history\n",
    "    df_history = pd.DataFrame(history)\n",
    "    df_history.to_csv(os.path.join(fold_save_dir, 'training_history.csv'), index=False)\n",
    "    print(f\"Training history saved to: {os.path.join(fold_save_dir, 'training_history.csv')}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"Fold {fold + 1} Training Completed!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Best model saved at: {best_model_path}\")\n",
    "\n",
    "    # Plot Confusion Matrix\n",
    "    best_cm = best_cm.T\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(best_cm, cmap=\"Blues\")\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.xticks(np.arange(len(class_names)), class_names, rotation=90)\n",
    "    plt.yticks(np.arange(len(class_names)), class_names)\n",
    "\n",
    "    plt.xlabel(\"True\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "\n",
    "    thresh = best_cm.max() / 2\n",
    "    for i in range(best_cm.shape[0]):\n",
    "        for j in range(best_cm.shape[1]):\n",
    "            if best_cm[i, j] > 0:\n",
    "                plt.text(j, i, f\"{best_cm[i, j]}\",\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if best_cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.savefig(os.path.join(fold_save_dir, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "    cm_norm = best_cm.astype(\"float\") / best_cm.sum(axis=0, keepdims=True)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.imshow(cm_norm, cmap=\"Blues\")\n",
    "    plt.title(\"Normalized Confusion Matrix\")\n",
    "    plt.colorbar()\n",
    "\n",
    "    plt.xticks(np.arange(len(class_names)), class_names, rotation=90)\n",
    "    plt.yticks(np.arange(len(class_names)), class_names)\n",
    "\n",
    "    plt.xlabel(\"True\")\n",
    "    plt.ylabel(\"Predicted\")\n",
    "\n",
    "    thresh = cm_norm.max() / 2\n",
    "    for i in range(cm_norm.shape[0]):\n",
    "        for j in range(cm_norm.shape[1]):\n",
    "            if cm_norm[i, j] > 0.009:\n",
    "                plt.text(j, i, f\"{cm_norm[i, j]:.2f}\",\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        color=\"white\" if cm_norm[i, j] > thresh else \"black\")\n",
    "                \n",
    "    plt.savefig(os.path.join(fold_save_dir, 'confusion_matrix_normalized.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "    # Plot training curves for this fold\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # Plot loss\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "    axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title(f'Fold {fold + 1} - Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Plot accuracy\n",
    "    axes[1].plot(history['train_acc'], label='Train Acc', marker='o')\n",
    "    axes[1].plot(history['val_acc'], label='Val Acc', marker='s')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title(f'Fold {fold + 1} - Training and Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    # Plot learning rate\n",
    "    axes[2].plot(history['lr'], label='Learning Rate', marker='o', color='green')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Learning Rate')\n",
    "    axes[2].set_title(f'Fold {fold + 1} - Learning Rate Schedule')\n",
    "    axes[2].set_yscale('log')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(fold_save_dir, 'training_plots.png'), dpi=300, bbox_inches='tight')\n",
    "\n",
    "    print(f\"Training plots saved to: {os.path.join(fold_save_dir, 'training_plots.png')}\")\n",
    "\n",
    "# FIM DO LOOP DE FOLDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f203f1a8454cfa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consolidate results from all folds\n",
    "results_df = pd.DataFrame(all_fold_results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CROSS-VALIDATION RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(\"STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Mean Best Val Accuracy: {results_df['best_val_acc'].mean():.2f}% ± {results_df['best_val_acc'].std():.2f}%\")\n",
    "print(f\"Mean Final Val Accuracy: {results_df['final_val_acc'].mean():.2f}% ± {results_df['final_val_acc'].std():.2f}%\")\n",
    "print(\n",
    "    f\"Mean Final Train Accuracy: {results_df['final_train_acc'].mean():.2f}% ± {results_df['final_train_acc'].std():.2f}%\")\n",
    "print(f\"Mean Epochs Trained: {results_df['epochs_trained'].mean():.1f} ± {results_df['epochs_trained'].std():.1f}\")\n",
    "\n",
    "with open(os.path.join(CONFIG['save_dir'], 'cross_validation_stats.txt'), 'w') as f:\n",
    "    f.write(f\"Mean Best Val Accuracy: {results_df['best_val_acc'].mean():.2f}% ± {results_df['best_val_acc'].std():.2f}%\\n\")\n",
    "    f.write(f\"Mean Final Val Accuracy: {results_df['final_val_acc'].mean():.2f}% ± {results_df['final_val_acc'].std():.2f}%\\n\")\n",
    "    f.write(f\"Mean Final Train Accuracy: {results_df['final_train_acc'].mean():.2f}% ± {results_df['final_train_acc'].std():.2f}%\\n\")\n",
    "    f.write(f\"Mean Final Val Loss: {results_df['final_val_loss'].mean():.2f}% ± {results_df['final_val_loss'].std():.2f}%\\n\")\n",
    "    f.write(f\"Mean Final Train Loss: {results_df['final_train_loss'].mean():.2f}% ± {results_df['final_train_loss'].std():.2f}%\\n\")\n",
    "\n",
    "# Save consolidated results\n",
    "results_df.to_csv(os.path.join(CONFIG['save_dir'], 'cross_validation_results.csv'), index=False)\n",
    "print(f\"\\nResults saved to: {os.path.join(CONFIG['save_dir'], 'cross_validation_results.csv')}\")\n",
    "\n",
    "# Plot comparison across folds\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Best validation accuracy per fold\n",
    "axes[0].bar(results_df['fold'], results_df['best_val_acc'])\n",
    "axes[0].axhline(y=results_df['best_val_acc'].mean(), color='r', linestyle='--', label='Mean')\n",
    "axes[0].set_xlabel('Fold')\n",
    "axes[0].set_ylabel('Best Validation Accuracy (%)')\n",
    "axes[0].set_title('Best Validation Accuracy per Fold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Epochs trained per fold\n",
    "axes[1].bar(results_df['fold'], results_df['epochs_trained'])\n",
    "axes[1].axhline(y=results_df['epochs_trained'].mean(), color='r', linestyle='--', label='Mean')\n",
    "axes[1].set_xlabel('Fold')\n",
    "axes[1].set_ylabel('Epochs Trained')\n",
    "axes[1].set_title('Epochs Trained per Fold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CONFIG['save_dir'], 'cross_validation_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Comparison plots saved to: {os.path.join(CONFIG['save_dir'], 'cross_validation_comparison.png')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is-recaptchav2-safe (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
