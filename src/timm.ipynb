{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2a77518f",
   "metadata": {},
   "source": [
    "# Is reCAPTCHAv2 Safe? - TIMM Implementation\n",
    "\n",
    "**Educational Research Project - UFABC Artificial Intelligence Course**\n",
    "\n",
    "This notebook implements a deep learning classifier using **PyTorch Image Models (timm)** to analyze the viability of reCAPTCHAv2 as a CAPTCHA method.\n",
    "\n",
    "## Model Options\n",
    "You can experiment with different pre-trained models by changing `model_name` in CONFIG:\n",
    "- `efficientnet_b0` - Efficient and fast (default)\n",
    "- `resnet50` - Classic architecture\n",
    "- `vit_small_patch16_224` - Vision Transformer\n",
    "- `convnext_tiny` - Modern ConvNet\n",
    "- `mobilenetv3_large_100` - Lightweight mobile model\n",
    "\n",
    "## Features\n",
    "- Transfer learning with timm pre-trained models\n",
    "- Data augmentation for improved generalization\n",
    "- Early stopping to prevent overfitting\n",
    "- Learning rate scheduling (Cosine Annealing)\n",
    "- MPS/CUDA/CPU support\n",
    "- Training visualization and metrics"
   ]
  },
  {
   "cell_type": "code",
   "id": "d7b37046",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T01:23:14.010616Z",
     "start_time": "2025-11-16T01:23:13.093838Z"
    }
   },
   "source": [
    "from utils.dataset_download import DatasetDownloader\n",
    "from utils.load_datasets import load_datasets\n",
    "\n",
    "dataset_downloader = DatasetDownloader(\"../datasets\")\n",
    "dataset_downloader.download_all()\n",
    "\n",
    "df = load_datasets(\"../datasets\")\n",
    "display(df.head())\n",
    "display(df['From'].value_counts())\n",
    "display(f\"Total images loaded: {len(df)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset AdityaJain1030/recaptcha-dataset already exists. Skipping download.\n",
      "Dataset nobodyPerfecZ/recaptchav2-29k already exists. Skipping download.\n",
      "Dataset cry2003/google-recaptcha-v2-images already exists. Skipping download.\n",
      "Dataset mikhailma/test-dataset already exists. Skipping download.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                               Image  \\\n",
       "0  ../datasets/google-recaptcha-v2-images/images/...   \n",
       "1  ../datasets/google-recaptcha-v2-images/images/...   \n",
       "2  ../datasets/google-recaptcha-v2-images/images/...   \n",
       "3  ../datasets/google-recaptcha-v2-images/images/...   \n",
       "4  ../datasets/google-recaptcha-v2-images/images/...   \n",
       "\n",
       "                                       Filename    Label  \\\n",
       "0      0de9e212-2460-4b55-bf30-f4bd9c158c23.jpg  Hydrant   \n",
       "1      5d15f820-c4b6-4403-8d21-2e4778072b03.jpg  Hydrant   \n",
       "2      1e6a809a-8fc3-4961-9114-c996fdf0eb79.jpg  Hydrant   \n",
       "3  Hydrant$bdac55d076bea3ba89bc9a1052331806.png  Hydrant   \n",
       "4      77e34738-b086-4b45-bffe-f76032d90592.jpg  Hydrant   \n",
       "\n",
       "                         From  \n",
       "0  google-recaptcha-v2-images  \n",
       "1  google-recaptcha-v2-images  \n",
       "2  google-recaptcha-v2-images  \n",
       "3  google-recaptcha-v2-images  \n",
       "4  google-recaptcha-v2-images  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Image</th>\n",
       "      <th>Filename</th>\n",
       "      <th>Label</th>\n",
       "      <th>From</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>../datasets/google-recaptcha-v2-images/images/...</td>\n",
       "      <td>0de9e212-2460-4b55-bf30-f4bd9c158c23.jpg</td>\n",
       "      <td>Hydrant</td>\n",
       "      <td>google-recaptcha-v2-images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>../datasets/google-recaptcha-v2-images/images/...</td>\n",
       "      <td>5d15f820-c4b6-4403-8d21-2e4778072b03.jpg</td>\n",
       "      <td>Hydrant</td>\n",
       "      <td>google-recaptcha-v2-images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>../datasets/google-recaptcha-v2-images/images/...</td>\n",
       "      <td>1e6a809a-8fc3-4961-9114-c996fdf0eb79.jpg</td>\n",
       "      <td>Hydrant</td>\n",
       "      <td>google-recaptcha-v2-images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>../datasets/google-recaptcha-v2-images/images/...</td>\n",
       "      <td>Hydrant$bdac55d076bea3ba89bc9a1052331806.png</td>\n",
       "      <td>Hydrant</td>\n",
       "      <td>google-recaptcha-v2-images</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>../datasets/google-recaptcha-v2-images/images/...</td>\n",
       "      <td>77e34738-b086-4b45-bffe-f76032d90592.jpg</td>\n",
       "      <td>Hydrant</td>\n",
       "      <td>google-recaptcha-v2-images</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "From\n",
       "google-recaptcha-v2-images    32265\n",
       "recaptchav2-29k               29568\n",
       "recaptcha-dataset             11774\n",
       "test-dataset                    279\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    },
    {
     "data": {
      "text/plain": [
       "'Total images loaded: 73886'"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T01:23:17.779817Z",
     "start_time": "2025-11-16T01:23:16.410912Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "max_images = 3000\n",
    "\n",
    "labels = df['Label'].unique()\n",
    "\n",
    "label_count = {label: 0 for label in labels}\n",
    "\n",
    "updt_df_dict = {\n",
    "    \"Image\": [],\n",
    "    \"Filename\": [],\n",
    "    \"Label\": [],\n",
    "    \"From\": []\n",
    "}\n",
    "\n",
    "# Create shared images directory once (outside the loop)\n",
    "shared_images_dir = Path(\"../timm_dataset_shared/images\")\n",
    "shared_images_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Create symlinks to all images once\n",
    "print(\"Creating shared images directory...\")\n",
    "for idx, row in df.iterrows():\n",
    "    if label_count[row['Label']] < max_images:\n",
    "        src = Path(row['Image']).absolute()\n",
    "        unique_filename = f\"{row['From']}_{row['Filename']}\"\n",
    "        dst = shared_images_dir / unique_filename\n",
    "\n",
    "        if not dst.exists():\n",
    "            os.symlink(src, dst)\n",
    "        label_count[row['Label']] += 1\n",
    "\n",
    "        updt_df_dict[\"Image\"].append(row[\"Image\"])\n",
    "        updt_df_dict[\"Filename\"].append(row[\"Filename\"])\n",
    "        updt_df_dict[\"Label\"].append(row[\"Label\"])\n",
    "        updt_df_dict[\"From\"].append(row[\"From\"])\n",
    "\n",
    "print(f\"Shared images directory created with {len(list(shared_images_dir.iterdir()))} images\")\n",
    "\n",
    "df = pd.DataFrame(updt_df_dict)\n",
    "df.to_parquet(\"../datasets/datasets_reduced.parquet\", index=False)"
   ],
   "id": "1dc9486fe1bfe8cd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating shared images directory...\n",
      "Shared images directory created with 26773 images\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T01:23:20.744070Z",
     "start_time": "2025-11-16T01:23:20.737340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "try:\n",
    "    display(df['Label'].value_counts())\n",
    "except NameError:\n",
    "    df = pd.read_parquet('../datasets/datasets_reduced.parquet', engine='pyarrow')\n",
    "    display(df['Label'].value_counts())"
   ],
   "id": "9084d20975c1d594",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Label\n",
       "Hydrant          3000\n",
       "Car              3000\n",
       "Traffic Light    3000\n",
       "Other            3000\n",
       "Bus              3000\n",
       "Bicycle          3000\n",
       "Crosswalk        3000\n",
       "Palm             2580\n",
       "Bridge           1831\n",
       "Stair             644\n",
       "Chimney           389\n",
       "Motorcycle        297\n",
       "Mountain           32\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data",
     "jetTransient": {
      "display_id": null
     }
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T01:23:37.417905Z",
     "start_time": "2025-11-16T01:23:23.903545Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "import shutil\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "shared_images_dir = Path(\"../timm_dataset_shared/images\")\n",
    "\n",
    "N_FOLDS = 5\n",
    "# Setup k-fold\n",
    "skf = StratifiedKFold(n_splits=N_FOLDS, shuffle=True, random_state=42)\n",
    "labels = df['Label'].unique()\n",
    "\n",
    "# Store results from all folds\n",
    "all_results = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(skf.split(df, df['Label'])):\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"FOLD {fold + 1}/{N_FOLDS}\")\n",
    "    print(f\"{'='*50}\")\n",
    "\n",
    "    # Split data for this fold\n",
    "    train_df = df.iloc[train_idx].reset_index(drop=True)\n",
    "    val_df = df.iloc[val_idx].reset_index(drop=True)\n",
    "\n",
    "    print(f\"Train: {len(train_df)}, Val: {len(val_df)}\")\n",
    "    print(f\"Train label distribution:\\n{train_df['Label'].value_counts()}\")\n",
    "    print(f\"Val label distribution:\\n{val_df['Label'].value_counts()}\")\n",
    "\n",
    "    # Create fold-specific dataset structure\n",
    "    dataset_root = Path(f\"../timm_dataset_fold{fold}\")\n",
    "    labels_file = dataset_root / \"labels.txt\"\n",
    "\n",
    "    dataset_root.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Build list of images with their splits for this fold\n",
    "    all_images = []\n",
    "\n",
    "    # Add training images\n",
    "    for idx, row in train_df.iterrows():\n",
    "        unique_filename = f\"{row['From']}_{row['Filename']}\"\n",
    "        all_images.append({\n",
    "            'filename': unique_filename,\n",
    "            'label': row['Label'],\n",
    "            'split': 'train'\n",
    "        })\n",
    "\n",
    "    # Add validation images\n",
    "    for idx, row in val_df.iterrows():\n",
    "        unique_filename = f\"{row['From']}_{row['Filename']}\"\n",
    "        all_images.append({\n",
    "            'filename': unique_filename,\n",
    "            'label': row['Label'],\n",
    "            'split': 'val'\n",
    "        })\n",
    "\n",
    "    # Create labels file with format: filename label split\n",
    "    with open(labels_file, 'w') as f:\n",
    "        f.write(\"filename\\tlabel\\tsplit\\n\")\n",
    "        for img_info in all_images:\n",
    "            f.write(f\"{img_info['filename']}\\t{img_info['label']}\\t{img_info['split']}\\n\")\n",
    "\n",
    "    # For TIMM classification, create train/val split directories\n",
    "    # with symlinks pointing to the shared images folder\n",
    "    train_dir = dataset_root / \"train\"\n",
    "    val_dir = dataset_root / \"val\"\n",
    "\n",
    "    # Remove old train/val if they exist\n",
    "    if train_dir.exists():\n",
    "        shutil.rmtree(train_dir)\n",
    "    if val_dir.exists():\n",
    "        shutil.rmtree(val_dir)\n",
    "\n",
    "    # Create label subdirectories\n",
    "    for label in labels:\n",
    "        (train_dir / label).mkdir(parents=True, exist_ok=True)\n",
    "        (val_dir / label).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Create symlinks in train/val pointing to shared images folder\n",
    "    for img_info in all_images:\n",
    "        src = (shared_images_dir / img_info['filename']).absolute()\n",
    "        if img_info['split'] == 'train':\n",
    "            dst = train_dir / img_info['label'] / img_info['filename']\n",
    "        else:\n",
    "            dst = val_dir / img_info['label'] / img_info['filename']\n",
    "\n",
    "        os.symlink(src, dst)\n",
    "\n",
    "    print(f\"Fold {fold + 1} dataset created!\")\n",
    "    print(f\"  - Labels file: {labels_file}\")"
   ],
   "id": "6b06de1170699a6a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "FOLD 1/5\n",
      "==================================================\n",
      "Train: 21418, Val: 5355\n",
      "Train label distribution:\n",
      "Label\n",
      "Hydrant          2400\n",
      "Car              2400\n",
      "Traffic Light    2400\n",
      "Other            2400\n",
      "Bus              2400\n",
      "Bicycle          2400\n",
      "Crosswalk        2400\n",
      "Palm             2064\n",
      "Bridge           1464\n",
      "Stair             516\n",
      "Chimney           311\n",
      "Motorcycle        237\n",
      "Mountain           26\n",
      "Name: count, dtype: int64\n",
      "Val label distribution:\n",
      "Label\n",
      "Hydrant          600\n",
      "Car              600\n",
      "Traffic Light    600\n",
      "Other            600\n",
      "Bus              600\n",
      "Bicycle          600\n",
      "Crosswalk        600\n",
      "Palm             516\n",
      "Bridge           367\n",
      "Stair            128\n",
      "Chimney           78\n",
      "Motorcycle        60\n",
      "Mountain           6\n",
      "Name: count, dtype: int64\n",
      "Fold 1 dataset created!\n",
      "  - Labels file: ../timm_dataset_fold0/labels.txt\n",
      "\n",
      "==================================================\n",
      "FOLD 2/5\n",
      "==================================================\n",
      "Train: 21418, Val: 5355\n",
      "Train label distribution:\n",
      "Label\n",
      "Hydrant          2400\n",
      "Car              2400\n",
      "Traffic Light    2400\n",
      "Other            2400\n",
      "Bus              2400\n",
      "Bicycle          2400\n",
      "Crosswalk        2400\n",
      "Palm             2064\n",
      "Bridge           1465\n",
      "Stair             515\n",
      "Chimney           312\n",
      "Motorcycle        237\n",
      "Mountain           25\n",
      "Name: count, dtype: int64\n",
      "Val label distribution:\n",
      "Label\n",
      "Hydrant          600\n",
      "Car              600\n",
      "Traffic Light    600\n",
      "Other            600\n",
      "Bus              600\n",
      "Bicycle          600\n",
      "Crosswalk        600\n",
      "Palm             516\n",
      "Bridge           366\n",
      "Stair            129\n",
      "Chimney           77\n",
      "Motorcycle        60\n",
      "Mountain           7\n",
      "Name: count, dtype: int64\n",
      "Fold 2 dataset created!\n",
      "  - Labels file: ../timm_dataset_fold1/labels.txt\n",
      "\n",
      "==================================================\n",
      "FOLD 3/5\n",
      "==================================================\n",
      "Train: 21418, Val: 5355\n",
      "Train label distribution:\n",
      "Label\n",
      "Hydrant          2400\n",
      "Car              2400\n",
      "Traffic Light    2400\n",
      "Other            2400\n",
      "Bus              2400\n",
      "Bicycle          2400\n",
      "Crosswalk        2400\n",
      "Palm             2064\n",
      "Bridge           1465\n",
      "Stair             515\n",
      "Chimney           311\n",
      "Motorcycle        238\n",
      "Mountain           25\n",
      "Name: count, dtype: int64\n",
      "Val label distribution:\n",
      "Label\n",
      "Hydrant          600\n",
      "Car              600\n",
      "Traffic Light    600\n",
      "Other            600\n",
      "Bus              600\n",
      "Bicycle          600\n",
      "Crosswalk        600\n",
      "Palm             516\n",
      "Bridge           366\n",
      "Stair            129\n",
      "Chimney           78\n",
      "Motorcycle        59\n",
      "Mountain           7\n",
      "Name: count, dtype: int64\n",
      "Fold 3 dataset created!\n",
      "  - Labels file: ../timm_dataset_fold2/labels.txt\n",
      "\n",
      "==================================================\n",
      "FOLD 4/5\n",
      "==================================================\n",
      "Train: 21419, Val: 5354\n",
      "Train label distribution:\n",
      "Label\n",
      "Hydrant          2400\n",
      "Car              2400\n",
      "Traffic Light    2400\n",
      "Other            2400\n",
      "Bus              2400\n",
      "Bicycle          2400\n",
      "Crosswalk        2400\n",
      "Palm             2064\n",
      "Bridge           1465\n",
      "Stair             515\n",
      "Chimney           311\n",
      "Motorcycle        238\n",
      "Mountain           26\n",
      "Name: count, dtype: int64\n",
      "Val label distribution:\n",
      "Label\n",
      "Hydrant          600\n",
      "Car              600\n",
      "Traffic Light    600\n",
      "Other            600\n",
      "Bus              600\n",
      "Bicycle          600\n",
      "Crosswalk        600\n",
      "Palm             516\n",
      "Bridge           366\n",
      "Stair            129\n",
      "Chimney           78\n",
      "Motorcycle        59\n",
      "Mountain           6\n",
      "Name: count, dtype: int64\n",
      "Fold 4 dataset created!\n",
      "  - Labels file: ../timm_dataset_fold3/labels.txt\n",
      "\n",
      "==================================================\n",
      "FOLD 5/5\n",
      "==================================================\n",
      "Train: 21419, Val: 5354\n",
      "Train label distribution:\n",
      "Label\n",
      "Hydrant          2400\n",
      "Car              2400\n",
      "Traffic Light    2400\n",
      "Other            2400\n",
      "Bus              2400\n",
      "Bicycle          2400\n",
      "Crosswalk        2400\n",
      "Palm             2064\n",
      "Bridge           1465\n",
      "Stair             515\n",
      "Chimney           311\n",
      "Motorcycle        238\n",
      "Mountain           26\n",
      "Name: count, dtype: int64\n",
      "Val label distribution:\n",
      "Label\n",
      "Hydrant          600\n",
      "Car              600\n",
      "Traffic Light    600\n",
      "Other            600\n",
      "Bus              600\n",
      "Bicycle          600\n",
      "Crosswalk        600\n",
      "Palm             516\n",
      "Bridge           366\n",
      "Stair            129\n",
      "Chimney           78\n",
      "Motorcycle        59\n",
      "Mountain           6\n",
      "Name: count, dtype: int64\n",
      "Fold 5 dataset created!\n",
      "  - Labels file: ../timm_dataset_fold4/labels.txt\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "8392653d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-16T01:23:44.612747Z",
     "start_time": "2025-11-16T01:23:42.968417Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import timm\n",
    "from timm.loss import LabelSmoothingCrossEntropy\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Configuration\n",
    "CONFIG = {\n",
    "    'model_name': 'efficientnet_b0',\n",
    "    'img_size': 224,\n",
    "    'batch_size': 32,\n",
    "    'epochs': 100,\n",
    "    'patience': 50,\n",
    "    'lr': 0.001,\n",
    "    'device': 'mps' if torch.backends.mps.is_available() else 'cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    'num_workers': 4,\n",
    "    'n_folds': 5,  # ADICIONAR\n",
    "    'save_dir': 'is_recaptchav2_safe/timm_experiment'\n",
    "}\n",
    "\n",
    "print(f\"Using device: {CONFIG['device']}\")\n",
    "print(f\"Model: {CONFIG['model_name']}\")\n",
    "\n",
    "# Create save directory\n",
    "Path(CONFIG['save_dir']).mkdir(parents=True, exist_ok=True)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mac/Documents/PythonProjects/MassUploadScript/.venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: mps\n",
      "Model: efficientnet_b0\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "2253074f",
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-11-16T01:23:49.336325Z"
    }
   },
   "source": [
    "# Store results from all folds\n",
    "all_fold_results = []\n",
    "\n",
    "\n",
    "# Training and validation functions (definir FORA do loop)\n",
    "def train_epoch(model, train_loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    pbar = tqdm(train_loader, desc='Training')\n",
    "    for inputs, labels in pbar:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "        pbar.set_postfix({\n",
    "            'loss': f'{running_loss / len(pbar):.4f}',\n",
    "            'acc': f'{100. * correct / total:.2f}%'\n",
    "        })\n",
    "\n",
    "    return running_loss / len(train_loader), 100. * correct / total\n",
    "\n",
    "\n",
    "def validate(model, val_loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pbar = tqdm(val_loader, desc='Validation')\n",
    "        for inputs, labels in pbar:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "            pbar.set_postfix({\n",
    "                'loss': f'{running_loss / len(pbar):.4f}',\n",
    "                'acc': f'{100. * correct / total:.2f}%'\n",
    "            })\n",
    "\n",
    "    return running_loss / len(val_loader), 100. * correct / total\n",
    "\n",
    "\n",
    "# INÍCIO DO LOOP DE FOLDS\n",
    "for fold in range(CONFIG['n_folds']):\n",
    "    print(f\"\\n{'=' * 60}\")\n",
    "    print(f\"PROCESSING FOLD {fold + 1}/{CONFIG['n_folds']}\")\n",
    "    print(f\"{'=' * 60}\")\n",
    "\n",
    "    # Update data directory for current fold\n",
    "    fold_data_dir = f'../timm_dataset_fold{fold}'\n",
    "    fold_save_dir = os.path.join(CONFIG['save_dir'], f'fold{fold}')\n",
    "    Path(fold_save_dir).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    # Data Transforms\n",
    "    train_transform = transforms.Compose([\n",
    "        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.RandomRotation(15),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    val_transform = transforms.Compose([\n",
    "        transforms.Resize((CONFIG['img_size'], CONFIG['img_size'])),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Load datasets for this fold\n",
    "    train_dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(fold_data_dir, 'train'),\n",
    "        transform=train_transform\n",
    "    )\n",
    "\n",
    "    val_dataset = datasets.ImageFolder(\n",
    "        root=os.path.join(fold_data_dir, 'val'),\n",
    "        transform=val_transform\n",
    "    )\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=True,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=CONFIG['batch_size'],\n",
    "        shuffle=False,\n",
    "        num_workers=CONFIG['num_workers'],\n",
    "        pin_memory=True\n",
    "    )\n",
    "\n",
    "    num_classes = len(train_dataset.classes)\n",
    "    class_names = train_dataset.classes\n",
    "\n",
    "    print(f\"\\nDataset Statistics:\")\n",
    "    print(f\"Number of classes: {num_classes}\")\n",
    "    print(f\"Classes: {class_names}\")\n",
    "    print(f\"Training samples: {len(train_dataset)}\")\n",
    "    print(f\"Validation samples: {len(val_dataset)}\")\n",
    "\n",
    "    # Create model using timm (NOVO modelo para cada fold)\n",
    "    model = timm.create_model(\n",
    "        CONFIG['model_name'],\n",
    "        pretrained=True,\n",
    "        num_classes=num_classes\n",
    "    )\n",
    "\n",
    "    model = model.to(CONFIG['device'])\n",
    "\n",
    "    # Loss function and optimizer\n",
    "    criterion = LabelSmoothingCrossEntropy(smoothing=0.1)\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CONFIG['lr'], weight_decay=0.01)\n",
    "\n",
    "    # Learning rate scheduler\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "        optimizer,\n",
    "        T_0=10,\n",
    "        T_mult=2,\n",
    "        eta_min=1e-6\n",
    "    )\n",
    "\n",
    "    print(f\"\\nModel created: {CONFIG['model_name']}\")\n",
    "    print(f\"Total parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    print(f\"Trainable parameters: {sum(p.numel() for p in model.parameters() if p.requires_grad):,}\")\n",
    "\n",
    "    # Training loop with early stopping\n",
    "    history = {\n",
    "        'train_loss': [],\n",
    "        'train_acc': [],\n",
    "        'val_loss': [],\n",
    "        'val_acc': [],\n",
    "        'lr': []\n",
    "    }\n",
    "\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    best_model_path = os.path.join(fold_save_dir, 'best.pt')\n",
    "    last_model_path = os.path.join(fold_save_dir, 'last.pt')\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"Starting Training - Fold {fold + 1}\")\n",
    "    print(\"=\" * 50)\n",
    "\n",
    "    for epoch in range(CONFIG['epochs']):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{CONFIG['epochs']}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(\n",
    "            model, train_loader, criterion, optimizer, CONFIG['device']\n",
    "        )\n",
    "\n",
    "        # Validate\n",
    "        val_loss, val_acc = validate(\n",
    "            model, val_loader, criterion, CONFIG['device']\n",
    "        )\n",
    "\n",
    "        # Update learning rate\n",
    "        scheduler.step()\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "\n",
    "        # Save history\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['train_acc'].append(train_acc)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        history['val_acc'].append(val_acc)\n",
    "        history['lr'].append(current_lr)\n",
    "\n",
    "        print(f\"\\nEpoch Summary:\")\n",
    "        print(f\"Train Loss: {train_loss:.4f} | Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f} | Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"Learning Rate: {current_lr:.6f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            torch.save({\n",
    "                'epoch': epoch,\n",
    "                'fold': fold,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'val_acc': val_acc,\n",
    "                'val_loss': val_loss,\n",
    "                'class_names': class_names\n",
    "            }, best_model_path)\n",
    "            print(f\"✓ New best model saved! Val Acc: {val_acc:.2f}%\")\n",
    "            patience_counter = 0\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            print(f\"Patience: {patience_counter}/{CONFIG['patience']}\")\n",
    "\n",
    "        # Save last model\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'fold': fold,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_acc': val_acc,\n",
    "            'val_loss': val_loss,\n",
    "            'class_names': class_names\n",
    "        }, last_model_path)\n",
    "\n",
    "        # Early stopping\n",
    "        if patience_counter >= CONFIG['patience']:\n",
    "            print(f\"\\nEarly stopping triggered after {epoch + 1} epochs\")\n",
    "            break\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    print(f\"Fold {fold + 1} Training Completed!\")\n",
    "    print(\"=\" * 50)\n",
    "    print(f\"Best validation accuracy: {best_val_acc:.2f}%\")\n",
    "    print(f\"Best model saved at: {best_model_path}\")\n",
    "\n",
    "    # Save fold results\n",
    "    fold_results = {\n",
    "        'fold': fold + 1,\n",
    "        'best_val_acc': best_val_acc,\n",
    "        'final_val_acc': val_acc,\n",
    "        'final_train_acc': train_acc,\n",
    "        'final_val_loss': val_loss,\n",
    "        'final_train_loss': train_loss,\n",
    "        'epochs_trained': epoch + 1\n",
    "    }\n",
    "    all_fold_results.append(fold_results)\n",
    "\n",
    "    # Save fold history\n",
    "    df_history = pd.DataFrame(history)\n",
    "    df_history.to_csv(os.path.join(fold_save_dir, 'training_history.csv'), index=False)\n",
    "    print(f\"Training history saved to: {os.path.join(fold_save_dir, 'training_history.csv')}\")\n",
    "\n",
    "    # Plot training curves for this fold\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "    # Plot loss\n",
    "    axes[0].plot(history['train_loss'], label='Train Loss', marker='o')\n",
    "    axes[0].plot(history['val_loss'], label='Val Loss', marker='s')\n",
    "    axes[0].set_xlabel('Epoch')\n",
    "    axes[0].set_ylabel('Loss')\n",
    "    axes[0].set_title(f'Fold {fold + 1} - Training and Validation Loss')\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True)\n",
    "\n",
    "    # Plot accuracy\n",
    "    axes[1].plot(history['train_acc'], label='Train Acc', marker='o')\n",
    "    axes[1].plot(history['val_acc'], label='Val Acc', marker='s')\n",
    "    axes[1].set_xlabel('Epoch')\n",
    "    axes[1].set_ylabel('Accuracy (%)')\n",
    "    axes[1].set_title(f'Fold {fold + 1} - Training and Validation Accuracy')\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True)\n",
    "\n",
    "    # Plot learning rate\n",
    "    axes[2].plot(history['lr'], label='Learning Rate', marker='o', color='green')\n",
    "    axes[2].set_xlabel('Epoch')\n",
    "    axes[2].set_ylabel('Learning Rate')\n",
    "    axes[2].set_title(f'Fold {fold + 1} - Learning Rate Schedule')\n",
    "    axes[2].set_yscale('log')\n",
    "    axes[2].legend()\n",
    "    axes[2].grid(True)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(fold_save_dir, 'training_plots.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "    print(f\"Training plots saved to: {os.path.join(fold_save_dir, 'training_plots.png')}\")\n",
    "\n",
    "# FIM DO LOOP DE FOLDS"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "PROCESSING FOLD 1/5\n",
      "============================================================\n",
      "\n",
      "Dataset Statistics:\n",
      "Number of classes: 13\n",
      "Classes: ['Bicycle', 'Bridge', 'Bus', 'Car', 'Chimney', 'Crosswalk', 'Hydrant', 'Motorcycle', 'Mountain', 'Other', 'Palm', 'Stair', 'Traffic Light']\n",
      "Training samples: 21418\n",
      "Validation samples: 5355\n",
      "\n",
      "Model created: efficientnet_b0\n",
      "Total parameters: 4,024,201\n",
      "Trainable parameters: 4,024,201\n",
      "\n",
      "==================================================\n",
      "Starting Training - Fold 1\n",
      "==================================================\n",
      "\n",
      "Epoch 1/100\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training:   0%|          | 0/670 [00:00<?, ?it/s]/Users/mac/Documents/PythonProjects/MassUploadScript/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:692: UserWarning: 'pin_memory' argument is set as true but not supported on MPS now, device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "Training:  11%|█         | 71/670 [00:41<04:20,  2.30it/s, loss=0.1746, acc=64.13%] "
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Consolidate results from all folds\n",
    "results_df = pd.DataFrame(all_fold_results)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"CROSS-VALIDATION RESULTS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "print(f\"\\n{'=' * 70}\")\n",
    "print(\"STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Mean Best Val Accuracy: {results_df['best_val_acc'].mean():.2f}% ± {results_df['best_val_acc'].std():.2f}%\")\n",
    "print(f\"Mean Final Val Accuracy: {results_df['final_val_acc'].mean():.2f}% ± {results_df['final_val_acc'].std():.2f}%\")\n",
    "print(\n",
    "    f\"Mean Final Train Accuracy: {results_df['final_train_acc'].mean():.2f}% ± {results_df['final_train_acc'].std():.2f}%\")\n",
    "print(f\"Mean Epochs Trained: {results_df['epochs_trained'].mean():.1f} ± {results_df['epochs_trained'].std():.1f}\")\n",
    "\n",
    "# Save consolidated results\n",
    "results_df.to_csv(os.path.join(CONFIG['save_dir'], 'cross_validation_results.csv'), index=False)\n",
    "print(f\"\\nResults saved to: {os.path.join(CONFIG['save_dir'], 'cross_validation_results.csv')}\")\n",
    "\n",
    "# Plot comparison across folds\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "\n",
    "# Best validation accuracy per fold\n",
    "axes[0].bar(results_df['fold'], results_df['best_val_acc'])\n",
    "axes[0].axhline(y=results_df['best_val_acc'].mean(), color='r', linestyle='--', label='Mean')\n",
    "axes[0].set_xlabel('Fold')\n",
    "axes[0].set_ylabel('Best Validation Accuracy (%)')\n",
    "axes[0].set_title('Best Validation Accuracy per Fold')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Epochs trained per fold\n",
    "axes[1].bar(results_df['fold'], results_df['epochs_trained'])\n",
    "axes[1].axhline(y=results_df['epochs_trained'].mean(), color='r', linestyle='--', label='Mean')\n",
    "axes[1].set_xlabel('Fold')\n",
    "axes[1].set_ylabel('Epochs Trained')\n",
    "axes[1].set_title('Epochs Trained per Fold')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(CONFIG['save_dir'], 'cross_validation_comparison.png'), dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"Comparison plots saved to: {os.path.join(CONFIG['save_dir'], 'cross_validation_comparison.png')}\")"
   ],
   "id": "7f203f1a8454cfa8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "is-reCAPTCHAv2-safe",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
